{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a06b3c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-22T03:51:23.621831Z",
     "iopub.status.busy": "2024-11-22T03:51:23.621440Z",
     "iopub.status.idle": "2024-11-22T03:51:24.625969Z",
     "shell.execute_reply": "2024-11-22T03:51:24.624474Z"
    },
    "papermill": {
     "duration": 1.014055,
     "end_time": "2024-11-22T03:51:24.628499",
     "exception": false,
     "start_time": "2024-11-22T03:51:23.614444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cwgan/pytorch/default/1/cWGAN-based oversampling tutorial.ipynb\n",
      "/kaggle/input/cwgan/pytorch/default/1/helpers.py\n",
      "/kaggle/input/cwgan/pytorch/default/1/models.py\n",
      "/kaggle/input/cwgan/pytorch/default/1/dataloader.py\n",
      "/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv\n",
      "/kaggle/input/dataset/cleaned_hmeq.csv\n",
      "/kaggle/input/dataset/UCI_Credit_Card.csv\n",
      "/kaggle/input/dataset/german.csv\n",
      "/kaggle/input/cwganagain/pytorch/default/1/helpers.py\n",
      "/kaggle/input/cwganagain/pytorch/default/1/models.py\n",
      "/kaggle/input/cwganagain/pytorch/default/1/dataloader.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56f701b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:51:24.635872Z",
     "iopub.status.busy": "2024-11-22T03:51:24.635414Z",
     "iopub.status.idle": "2024-11-22T03:51:26.797692Z",
     "shell.execute_reply": "2024-11-22T03:51:26.796298Z"
    },
    "papermill": {
     "duration": 2.168952,
     "end_time": "2024-11-22T03:51:26.800602",
     "exception": false,
     "start_time": "2024-11-22T03:51:24.631650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline using make_pipeline from imblearn\n",
    "smote_tomek_pipeline = make_pipeline(\n",
    "    SMOTE(),       # Apply SMOTE to oversample the minority class\n",
    "    #TomekLinks()   # Apply Tomek Links to clean the data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968b0cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:51:26.808498Z",
     "iopub.status.busy": "2024-11-22T03:51:26.807883Z",
     "iopub.status.idle": "2024-11-22T03:51:27.313387Z",
     "shell.execute_reply": "2024-11-22T03:51:27.312241Z"
    },
    "papermill": {
     "duration": 0.512331,
     "end_time": "2024-11-22T03:51:27.315967",
     "exception": false,
     "start_time": "2024-11-22T03:51:26.803636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    make_scorer\n",
    ")\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class ModelEvaluatorWithLibrary:\n",
    "    def __init__(self, models, threshold=0.5, cv_splits=5):\n",
    "        self.models = models\n",
    "        self.threshold = threshold\n",
    "        self.cv_splits = cv_splits\n",
    "\n",
    "    def evaluate_model_with_cv(self, X, y, model, scoring_metrics):\n",
    "        \"\"\"\n",
    "        Perform cross-validation using the provided metrics.\n",
    "        \"\"\"\n",
    "        cv = StratifiedKFold(n_splits=self.cv_splits, shuffle=True, random_state=42)\n",
    "        cv_results = cross_validate(\n",
    "            model, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False\n",
    "        )\n",
    "        \n",
    "        # Mean scores for each metric\n",
    "        model_scores = {metric: cv_results[f'test_{metric}'].mean() for metric in scoring_metrics}\n",
    "        return model_scores\n",
    "\n",
    "    def evaluate_model_on_test(self, X_train, y_train, X_test, y_test, model):\n",
    "        \"\"\"\n",
    "        Train the model and evaluate it on the test set.\n",
    "        \"\"\"\n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test)\n",
    "        y_pred = (y_prob >= self.threshold).astype(int)\n",
    "\n",
    "        scores = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "            'auc_roc': roc_auc_score(y_test, y_prob),\n",
    "        }\n",
    "\n",
    "        return scores, y_pred\n",
    "\n",
    "    def score_models(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate all models on cross-validation and the test set.\n",
    "        \"\"\"\n",
    "        scoring_metrics = {\n",
    "            'f1': 'f1',\n",
    "            'accuracy': 'accuracy',\n",
    "            'auc_roc': 'roc_auc'\n",
    "        }\n",
    "\n",
    "        scores = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Evaluating model: {name}\")\n",
    "            \n",
    "            # Cross-validation scores\n",
    "            cv_scores = self.evaluate_model_with_cv(X_train, y_train, model, scoring_metrics)\n",
    "            \n",
    "            # Test set evaluation\n",
    "            test_scores, y_pred = self.evaluate_model_on_test(X_train, y_train, X_test, y_test, model)\n",
    "            \n",
    "            # Store both cross-validation and test set results\n",
    "            scores[name] = {\n",
    "                #'cross_val': cv_scores,\n",
    "                'test': test_scores\n",
    "            }\n",
    "            \n",
    "            # Plot confusion matrix for the current model\n",
    "            #print(f\"Confusion Matrix for {name}:\")\n",
    "            #self.plot_confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def plot_confusion_matrix(self, y_test, y_pred, labels):\n",
    "        \"\"\"\n",
    "        Plot the confusion matrix.\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd12b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:51:27.323266Z",
     "iopub.status.busy": "2024-11-22T03:51:27.322666Z",
     "iopub.status.idle": "2024-11-22T03:51:27.328017Z",
     "shell.execute_reply": "2024-11-22T03:51:27.326840Z"
    },
    "papermill": {
     "duration": 0.011414,
     "end_time": "2024-11-22T03:51:27.330138",
     "exception": false,
     "start_time": "2024-11-22T03:51:27.318724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854008b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:51:27.336995Z",
     "iopub.status.busy": "2024-11-22T03:51:27.336593Z",
     "iopub.status.idle": "2024-11-22T03:51:28.992285Z",
     "shell.execute_reply": "2024-11-22T03:51:28.990896Z"
    },
    "papermill": {
     "duration": 1.662714,
     "end_time": "2024-11-22T03:51:28.995489",
     "exception": false,
     "start_time": "2024-11-22T03:51:27.332775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419aa26a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:51:29.006481Z",
     "iopub.status.busy": "2024-11-22T03:51:29.005143Z",
     "iopub.status.idle": "2024-11-22T09:19:23.510342Z",
     "shell.execute_reply": "2024-11-22T09:19:23.507119Z"
    },
    "papermill": {
     "duration": 19674.517896,
     "end_time": "2024-11-22T09:19:23.517088",
     "exception": false,
     "start_time": "2024-11-22T03:51:28.999192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/dataset/german.csv\n",
      "\n",
      "Status_loan\n",
      "700\n",
      "300\n",
      "Balanced X_train shape: (800, 61)\n",
      "Balanced y_train shape: (800,)\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "Evaluating model: BalancedRandomForestClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.78, 'f1': 0.5510204081632654, 'auc_roc': 0.7738690476190477}}, 'XGBClassifier': {'test': {'accuracy': 0.75, 'f1': 0.576271186440678, 'auc_roc': 0.7825}}, 'CatBoostClassifier': {'test': {'accuracy': 0.77, 'f1': 0.640625, 'auc_roc': 0.8141666666666667}}, 'LightGBMClassifier': {'test': {'accuracy': 0.73, 'f1': 0.55, 'auc_roc': 0.7602380952380953}}, 'StackingClassifier': {'test': {'accuracy': 0.73, 'f1': 0.6197183098591549, 'auc_roc': 0.8038095238095238}}, 'BalancedRandomForestClassifier': {'test': {'accuracy': 0.64, 'f1': 0.5662650602409638, 'auc_roc': 0.7732738095238095}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/dataset/cleaned_hmeq.csv\n",
      "\n",
      "BAD\n",
      "4771\n",
      "1189\n",
      "Balanced X_train shape: (4768, 18)\n",
      "Balanced y_train shape: (4768,)\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "Evaluating model: BalancedRandomForestClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.9161073825503355, 'f1': 0.7630331753554502, 'auc_roc': 0.970414266335465}}, 'XGBClassifier': {'test': {'accuracy': 0.9354026845637584, 'f1': 0.8405797101449276, 'auc_roc': 0.9719447527438648}}, 'CatBoostClassifier': {'test': {'accuracy': 0.9203020134228188, 'f1': 0.8140900195694716, 'auc_roc': 0.9694343146063458}}, 'LightGBMClassifier': {'test': {'accuracy': 0.9194630872483222, 'f1': 0.8095238095238094, 'auc_roc': 0.9680601800468615}}, 'StackingClassifier': {'test': {'accuracy': 0.927013422818792, 'f1': 0.835538752362949, 'auc_roc': 0.9741072529640786}}, 'BalancedRandomForestClassifier': {'test': {'accuracy': 0.8942953020134228, 'f1': 0.7797202797202797, 'auc_roc': 0.9649067174039427}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/dataset/UCI_Credit_Card.csv\n",
      "\n",
      "default.payment.next.month\n",
      "23364\n",
      "6636\n",
      "Balanced X_train shape: (24000, 23)\n",
      "Balanced y_train shape: (24000,)\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "Evaluating model: BalancedRandomForestClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.808, 'f1': 0.44401544401544407, 'auc_roc': 0.7605148368725337}}, 'XGBClassifier': {'test': {'accuracy': 0.7525, 'f1': 0.5045045045045045, 'auc_roc': 0.7468456658535275}}, 'CatBoostClassifier': {'test': {'accuracy': 0.7688333333333334, 'f1': 0.5328393398450656, 'auc_roc': 0.7671796533211763}}, 'LightGBMClassifier': {'test': {'accuracy': 0.764, 'f1': 0.5335968379446641, 'auc_roc': 0.7698547557349367}}, 'StackingClassifier': {'test': {'accuracy': 0.7526666666666667, 'f1': 0.5267857142857142, 'auc_roc': 0.7722057205924591}}, 'BalancedRandomForestClassifier': {'test': {'accuracy': 0.7073333333333334, 'f1': 0.5072951739618405, 'auc_roc': 0.7684853955066794}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv\n",
      "\n",
      "TARGET\n",
      "90596\n",
      "7922\n",
      "Balanced X_train shape: (78814, 1358)\n",
      "Balanced y_train shape: (78814,)\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "Evaluating model: BalancedRandomForestClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.9233150629313845, 'f1': 0.09030704394942805, 'auc_roc': 0.7162370113942962}}, 'XGBClassifier': {'test': {'accuracy': 0.8158749492488835, 'f1': 0.26854838709677425, 'auc_roc': 0.7016994935558677}}, 'CatBoostClassifier': {'test': {'accuracy': 0.8212038164839627, 'f1': 0.2875631951466127, 'auc_roc': 0.7284693652864184}}, 'LightGBMClassifier': {'test': {'accuracy': 0.7430470970361348, 'f1': 0.2562068458939327, 'auc_roc': 0.722665744085446}}, 'StackingClassifier': {'test': {'accuracy': 0.7176207876573285, 'f1': 0.26635021097046413, 'auc_roc': 0.748331235924365}}, 'BalancedRandomForestClassifier': {'test': {'accuracy': 0.6527608607389362, 'f1': 0.23859336746049414, 'auc_roc': 0.7312927320946775}}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "paths = ['/kaggle/input/dataset/german.csv', '/kaggle/input/dataset/cleaned_hmeq.csv', '/kaggle/input/dataset/UCI_Credit_Card.csv', '/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv']\n",
    "\n",
    "for path in paths:\n",
    "    print('-'*100)\n",
    "    print('-'*100)\n",
    "    print(f'DATASET: {path}')\n",
    "    print('')\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    if path == '/kaggle/input/dataset/german.csv':\n",
    "        target_col = 'Status_loan'\n",
    "        #df = df.drop('')\n",
    "    elif path == '/kaggle/input/dataset/cleaned_hmeq.csv':\n",
    "        target_col = 'BAD'\n",
    "        #df = df.drop('')\n",
    "    elif path == '/kaggle/input/dataset/UCI_Credit_Card.csv':\n",
    "        target_col = 'default.payment.next.month'\n",
    "        df = df.drop('ID', axis=1)\n",
    "    elif path == '/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv':\n",
    "        target_col = 'TARGET'\n",
    "        df = df.drop('SK_ID_CURR', axis=1)\n",
    "        y = df[target_col]\n",
    "        df, temp = train_test_split(df, test_size=0.6, random_state=2024, stratify=y) #thuc hanh tren bo nho 100000 (/200000) samples\n",
    "        del temp, y\n",
    "\n",
    "    # Define columns dynamically based on data types\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Remove target column from cat_cols or num_cols if present\n",
    "    if target_col in cat_cols:\n",
    "        cat_cols.remove(target_col)\n",
    "    elif target_col in num_cols:\n",
    "        num_cols.remove(target_col)\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].astype(str)\n",
    "    \n",
    "    X = df.loc[:, num_cols + cat_cols]\n",
    "    y = df[target_col]\n",
    "    \n",
    "    print(target_col)\n",
    "    print(y[y==0].count())\n",
    "    print(y[y==1].count())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024, stratify=y)\n",
    "    # Define numerical and categorical column transformers\n",
    "    num_prep = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                             MinMaxScaler())\n",
    "    \n",
    "    # Using OrdinalEncoder for numerical-like encoding of categorical columns\n",
    "    cat_prep = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
    "                             OneHotEncoder())\n",
    "    \n",
    "    # Combine both transformers into a ColumnTransformer\n",
    "    prep = ColumnTransformer([\n",
    "        ('num', num_prep, num_cols),\n",
    "        ('cat', cat_prep, cat_cols)\n",
    "        ],\n",
    "        remainder='drop')\n",
    "    \n",
    "    # Apply transformations to training and test sets\n",
    "    X_train_trans = prep.fit_transform(X_train)\n",
    "    X_test_trans = prep.transform(X_test)\n",
    "\n",
    "    #X_train_trans, y_train = smote_tomek_pipeline.fit_resample(X_train_trans, y_train)\n",
    "\n",
    "    # Output the shapes of the balanced datasets\n",
    "    print(f\"Balanced X_train shape: {X_train_trans.shape}\")\n",
    "    print(f\"Balanced y_train shape: {y_train.shape}\")\n",
    "\n",
    "    X_train = X_train_trans\n",
    "    X_test = X_test_trans\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y),\n",
    "        y=y\n",
    "        )\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Updated models\n",
    "    models = {\n",
    "        'RandomForestClassifier': RandomForestClassifier(\n",
    "            random_state=RANDOM_STATE, \n",
    "            class_weight=\"balanced\"\n",
    "        ),\n",
    "        'XGBClassifier': XGBClassifier(\n",
    "            random_state=RANDOM_STATE, \n",
    "            scale_pos_weight=class_weights[1] / class_weights[0]  # Adjusted for imbalance\n",
    "        ),\n",
    "        'CatBoostClassifier': CatBoostClassifier(\n",
    "            verbose=False, \n",
    "            random_state=RANDOM_STATE, \n",
    "            class_weights=class_weights\n",
    "        ),\n",
    "        'LightGBMClassifier': LGBMClassifier(\n",
    "            random_state=RANDOM_STATE, \n",
    "            class_weight=\"balanced\",\n",
    "            verbose=-1\n",
    "        ),\n",
    "        'StackingClassifier': StackingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', RandomForestClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\")),\n",
    "                ('xgb', XGBClassifier(random_state=RANDOM_STATE, scale_pos_weight=class_weights[1] / class_weights[0])),\n",
    "                ('catboost', CatBoostClassifier(verbose=False, random_state=RANDOM_STATE, class_weights=class_weights)),\n",
    "                ('lgbm', LGBMClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\", verbose=-1))\n",
    "            ],\n",
    "            final_estimator=LogisticRegression(class_weight=\"balanced\"),\n",
    "            cv=5\n",
    "        ),\n",
    "        'BalancedRandomForestClassifier': BalancedRandomForestClassifier(\n",
    "            random_state=RANDOM_STATE, sampling_strategy='not minority', replacement=True, bootstrap=False\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Initialize evaluator\n",
    "    evaluator = ModelEvaluatorWithLibrary(models=models)\n",
    "    \n",
    "    scores = evaluator.score_models(X_train, y_train, X_test, y_test)\n",
    "    print(scores)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6130170,
     "sourceId": 9965318,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 170908,
     "modelInstanceId": 148393,
     "sourceId": 174310,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 170958,
     "modelInstanceId": 148442,
     "sourceId": 174360,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19685.087785,
   "end_time": "2024-11-22T09:19:25.769433",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-22T03:51:20.681648",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

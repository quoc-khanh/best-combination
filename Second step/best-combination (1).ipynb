{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c900f90",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-22T03:03:55.322720Z",
     "iopub.status.busy": "2024-11-22T03:03:55.322267Z",
     "iopub.status.idle": "2024-11-22T03:03:56.472829Z",
     "shell.execute_reply": "2024-11-22T03:03:56.471457Z"
    },
    "papermill": {
     "duration": 1.159991,
     "end_time": "2024-11-22T03:03:56.475275",
     "exception": false,
     "start_time": "2024-11-22T03:03:55.315284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cwganagain/pytorch/default/1/helpers.py\n",
      "/kaggle/input/cwganagain/pytorch/default/1/models.py\n",
      "/kaggle/input/cwganagain/pytorch/default/1/dataloader.py\n",
      "/kaggle/input/cwgan/pytorch/default/1/cWGAN-based oversampling tutorial.ipynb\n",
      "/kaggle/input/cwgan/pytorch/default/1/helpers.py\n",
      "/kaggle/input/cwgan/pytorch/default/1/models.py\n",
      "/kaggle/input/cwgan/pytorch/default/1/dataloader.py\n",
      "/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv\n",
      "/kaggle/input/dataset/cleaned_hmeq.csv\n",
      "/kaggle/input/dataset/UCI_Credit_Card.csv\n",
      "/kaggle/input/dataset/german.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f22e90",
   "metadata": {
    "papermill": {
     "duration": 0.002611,
     "end_time": "2024-11-22T03:03:56.481066",
     "exception": false,
     "start_time": "2024-11-22T03:03:56.478455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We choose these models:\\\n",
    "RandomForestClassifier \\\n",
    "XGBoost\\\n",
    "CatBoost\\\n",
    "LightGBM\\\n",
    "StackingClassifier\\\n",
    "\n",
    "SMOTE (oversampling)\\\n",
    "ClusterCentroid (undersampling)\\\n",
    "SMOTEENN (hybrid: OS and US)\\\n",
    "cWGAN (NN)\\\n",
    "\n",
    "Balanced Random Forest (ensemble)\\\n",
    "Class Weights \\ass Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c31238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:03:56.488427Z",
     "iopub.status.busy": "2024-11-22T03:03:56.487874Z",
     "iopub.status.idle": "2024-11-22T03:03:58.953605Z",
     "shell.execute_reply": "2024-11-22T03:03:58.952277Z"
    },
    "papermill": {
     "duration": 2.472417,
     "end_time": "2024-11-22T03:03:58.956236",
     "exception": false,
     "start_time": "2024-11-22T03:03:56.483819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# SMOTE for oversampling\n",
    "smote_pipeline = make_pipeline(\n",
    "    SMOTE()  # Apply SMOTE to oversample the minority class\n",
    ")\n",
    "\n",
    "# ClusterCentroids for undersampling\n",
    "cluster_centroid_pipeline = make_pipeline(\n",
    "    ClusterCentroids()  # Apply ClusterCentroids to undersample the majority class\n",
    ")\n",
    "\n",
    "# SMOTEENN for hybrid oversampling and undersampling\n",
    "smoteenn_pipeline = make_pipeline(\n",
    "    SMOTEENN()  # Apply SMOTEENN to balance the dataset\n",
    ")\n",
    "\n",
    "# SMOTETomek for hybrid oversampling and undersampling\n",
    "smotetomek_pipeline = make_pipeline(\n",
    "    SMOTETomek()  # Apply SMOTETomek to balance the dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c914bfe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:03:58.963922Z",
     "iopub.status.busy": "2024-11-22T03:03:58.963383Z",
     "iopub.status.idle": "2024-11-22T03:03:59.519196Z",
     "shell.execute_reply": "2024-11-22T03:03:59.518012Z"
    },
    "papermill": {
     "duration": 0.56269,
     "end_time": "2024-11-22T03:03:59.521873",
     "exception": false,
     "start_time": "2024-11-22T03:03:58.959183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    make_scorer\n",
    ")\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class ModelEvaluatorWithLibrary:\n",
    "    def __init__(self, models, threshold=0.5, cv_splits=5):\n",
    "        self.models = models\n",
    "        self.threshold = threshold\n",
    "        self.cv_splits = cv_splits\n",
    "\n",
    "    def evaluate_model_with_cv(self, X, y, model, scoring_metrics):\n",
    "        \"\"\"\n",
    "        Perform cross-validation using the provided metrics.\n",
    "        \"\"\"\n",
    "        cv = StratifiedKFold(n_splits=self.cv_splits, shuffle=True, random_state=42)\n",
    "        cv_results = cross_validate(\n",
    "            model, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False\n",
    "        )\n",
    "        \n",
    "        # Mean scores for each metric\n",
    "        model_scores = {metric: cv_results[f'test_{metric}'].mean() for metric in scoring_metrics}\n",
    "        return model_scores\n",
    "\n",
    "    def evaluate_model_on_test(self, X_train, y_train, X_test, y_test, model):\n",
    "        \"\"\"\n",
    "        Train the model and evaluate it on the test set.\n",
    "        \"\"\"\n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test)\n",
    "        y_pred = (y_prob >= self.threshold).astype(int)\n",
    "\n",
    "        scores = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "            'auc_roc': roc_auc_score(y_test, y_prob),\n",
    "        }\n",
    "\n",
    "        return scores, y_pred\n",
    "\n",
    "    def score_models(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate all models on cross-validation and the test set.\n",
    "        \"\"\"\n",
    "        scoring_metrics = {\n",
    "            'f1': 'f1',\n",
    "            'accuracy': 'accuracy',\n",
    "            'auc_roc': 'roc_auc'\n",
    "        }\n",
    "\n",
    "        scores = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Evaluating model: {name}\")\n",
    "            \n",
    "            # Cross-validation scores\n",
    "            cv_scores = self.evaluate_model_with_cv(X_train, y_train, model, scoring_metrics)\n",
    "            \n",
    "            # Test set evaluation\n",
    "            test_scores, y_pred = self.evaluate_model_on_test(X_train, y_train, X_test, y_test, model)\n",
    "            \n",
    "            # Store both cross-validation and test set results\n",
    "            scores[name] = {\n",
    "                #'cross_val': cv_scores,\n",
    "                'test': test_scores\n",
    "            }\n",
    "            \n",
    "            # Plot confusion matrix for the current model\n",
    "            #print(f\"Confusion Matrix for {name}:\")\n",
    "            #self.plot_confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def plot_confusion_matrix(self, y_test, y_pred, labels):\n",
    "        \"\"\"\n",
    "        Plot the confusion matrix.\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "637d88d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:03:59.529966Z",
     "iopub.status.busy": "2024-11-22T03:03:59.529420Z",
     "iopub.status.idle": "2024-11-22T03:03:59.534498Z",
     "shell.execute_reply": "2024-11-22T03:03:59.533404Z"
    },
    "papermill": {
     "duration": 0.011841,
     "end_time": "2024-11-22T03:03:59.536861",
     "exception": false,
     "start_time": "2024-11-22T03:03:59.525020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e491507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:03:59.544171Z",
     "iopub.status.busy": "2024-11-22T03:03:59.543793Z",
     "iopub.status.idle": "2024-11-22T03:04:01.291622Z",
     "shell.execute_reply": "2024-11-22T03:04:01.290491Z"
    },
    "papermill": {
     "duration": 1.754347,
     "end_time": "2024-11-22T03:04:01.294105",
     "exception": false,
     "start_time": "2024-11-22T03:03:59.539758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'XGBClassifier': XGBClassifier(random_state=RANDOM_STATE),\n",
    "    'CatBoostClassifier': CatBoostClassifier(verbose=False, random_state=RANDOM_STATE),\n",
    "    'LightGBMClassifier': LGBMClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'StackingClassifier': StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    "            ('xgb', XGBClassifier(random_state=RANDOM_STATE)),\n",
    "            ('catboost', CatBoostClassifier(verbose=False, random_state=RANDOM_STATE)),\n",
    "            ('lgbm', LGBMClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=-1\n",
    "            ))\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=5\n",
    "    )\n",
    "}\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluatorWithLibrary(models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521f701b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:04:01.301943Z",
     "iopub.status.busy": "2024-11-22T03:04:01.301311Z",
     "iopub.status.idle": "2024-11-22T03:17:43.580086Z",
     "shell.execute_reply": "2024-11-22T03:17:43.575909Z"
    },
    "papermill": {
     "duration": 822.292763,
     "end_time": "2024-11-22T03:17:43.589720",
     "exception": false,
     "start_time": "2024-11-22T03:04:01.296957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/dataset/german.csv\n",
      "BALANCING METHOD: no\n",
      "\n",
      "Status_loan\n",
      "700\n",
      "300\n",
      "Bmethod is 'no'\n",
      "Balanced X_train shape: (800, 61)\n",
      "Balanced y_train shape: (800,)\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.755, 'f1': 0.514851485148515, 'auc_roc': 0.7687499999999999}}, 'XGBClassifier': {'test': {'accuracy': 0.76, 'f1': 0.5555555555555556, 'auc_roc': 0.7683333333333332}}, 'CatBoostClassifier': {'test': {'accuracy': 0.755, 'f1': 0.5420560747663552, 'auc_roc': 0.800595238095238}}, 'LightGBMClassifier': {'test': {'accuracy': 0.73, 'f1': 0.5, 'auc_roc': 0.7666666666666667}}, 'StackingClassifier': {'test': {'accuracy': 0.765, 'f1': 0.5523809523809524, 'auc_roc': 0.7891666666666667}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/dataset/cleaned_hmeq.csv\n",
      "BALANCING METHOD: no\n",
      "\n",
      "BAD\n",
      "4771\n",
      "1189\n",
      "Bmethod is 'no'\n",
      "Balanced X_train shape: (4768, 18)\n",
      "Balanced y_train shape: (4768,)\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.9203020134228188, 'f1': 0.7754137115839244, 'auc_roc': 0.9736998573014111}}, 'XGBClassifier': {'test': {'accuracy': 0.9303691275167785, 'f1': 0.8151447661469934, 'auc_roc': 0.9686151190035763}}, 'CatBoostClassifier': {'test': {'accuracy': 0.9253355704697986, 'f1': 0.7954022988505747, 'auc_roc': 0.9719931997956416}}, 'LightGBMClassifier': {'test': {'accuracy': 0.9194630872483222, 'f1': 0.7828054298642534, 'auc_roc': 0.96579638144566}}, 'StackingClassifier': {'test': {'accuracy': 0.9286912751677853, 'f1': 0.8106904231625836, 'auc_roc': 0.975952645209027}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/dataset/UCI_Credit_Card.csv\n",
      "BALANCING METHOD: no\n",
      "\n",
      "default.payment.next.month\n",
      "23364\n",
      "6636\n",
      "Bmethod is 'no'\n",
      "Balanced X_train shape: (24000, 23)\n",
      "Balanced y_train shape: (24000,)\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.8098333333333333, 'f1': 0.46356370474847197, 'auc_roc': 0.7603930030796293}}, 'XGBClassifier': {'test': {'accuracy': 0.806, 'f1': 0.44571428571428573, 'auc_roc': 0.7541484366168361}}, 'CatBoostClassifier': {'test': {'accuracy': 0.8111666666666667, 'f1': 0.4539759036144579, 'auc_roc': 0.7680104775449274}}, 'LightGBMClassifier': {'test': {'accuracy': 0.8146666666666667, 'f1': 0.4633204633204633, 'auc_roc': 0.7680539377794577}}, 'StackingClassifier': {'test': {'accuracy': 0.814, 'f1': 0.4571984435797665, 'auc_roc': 0.7730347709290862}}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "paths = ['/kaggle/input/dataset/german.csv', '/kaggle/input/dataset/cleaned_hmeq.csv', '/kaggle/input/dataset/UCI_Credit_Card.csv']#, '/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv']\n",
    "balmethods = ['no']#, 'smote', 'cc', 'smoteenn', 'smotetomek']\n",
    "for path in paths:\n",
    "    for balmethod in balmethods:\n",
    "        print('-'*100)\n",
    "        print('-'*100)\n",
    "        print(f'DATASET: {path}')\n",
    "        print(f'BALANCING METHOD: {balmethod}')\n",
    "        print('')\n",
    "        df = pd.read_csv(path)\n",
    "    \n",
    "        df = df.replace([np.inf, -np.inf], 0)\n",
    "        \n",
    "        if path == '/kaggle/input/dataset/german.csv':\n",
    "            target_col = 'Status_loan'\n",
    "            #df = df.drop('')\n",
    "        elif path == '/kaggle/input/dataset/cleaned_hmeq.csv':\n",
    "            target_col = 'BAD'\n",
    "            #df = df.drop('')\n",
    "        elif path == '/kaggle/input/dataset/UCI_Credit_Card.csv':\n",
    "            target_col = 'default.payment.next.month'\n",
    "            df = df.drop('ID', axis=1)\n",
    "        elif path == '/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv':\n",
    "            target_col = 'TARGET'\n",
    "            df = df.drop('SK_ID_CURR', axis=1)\n",
    "            df, temp = train_test_split(df, test_size=0., random_state=2024, stratify=y) #thuc hanh tren bo nho 100000 (/200000) samples\n",
    "        \n",
    "        # Define columns dynamically based on data types\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        \n",
    "        # Remove target column from cat_cols or num_cols if present\n",
    "        if target_col in cat_cols:\n",
    "            cat_cols.remove(target_col)\n",
    "        elif target_col in num_cols:\n",
    "            num_cols.remove(target_col)\n",
    "        for col in cat_cols:\n",
    "            df[col] = df[col].astype(str)\n",
    "        \n",
    "        X = df.loc[:, num_cols + cat_cols]\n",
    "        y = df[target_col]\n",
    "        \n",
    "        print(target_col)\n",
    "        print(y[y==0].count())\n",
    "        print(y[y==1].count())\n",
    " \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024, stratify=y)\n",
    "        \n",
    "        # Define numerical and categorical column transformers\n",
    "        num_prep = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                                 MinMaxScaler())\n",
    "        \n",
    "        # Using OrdinalEncoder for numerical-like encoding of categorical columns\n",
    "        cat_prep = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
    "                                 OneHotEncoder())\n",
    "        \n",
    "        # Combine both transformers into a ColumnTransformer\n",
    "        prep = ColumnTransformer([\n",
    "            ('num', num_prep, num_cols),\n",
    "            ('cat', cat_prep, cat_cols)\n",
    "            ],\n",
    "            remainder='drop')\n",
    "        \n",
    "        # Apply transformations to training and test sets\n",
    "        X_train_trans = prep.fit_transform(X_train)\n",
    "        X_test_trans = prep.transform(X_test)\n",
    "        if balmethod == 'smote':\n",
    "            X_train_trans, y_train = smote_pipeline.fit_resample(X_train_trans, y_train)\n",
    "        elif balmethod == 'cc':\n",
    "            X_train_trans, y_train = cluster_centroid_pipeline.fit_resample(X_train_trans, y_train)\n",
    "        elif balmethod == 'smoteenn':\n",
    "            X_train_trans, y_train = smoteenn_pipeline.fit_resample(X_train_trans, y_train)\n",
    "        elif balmethod == 'smotetomek':\n",
    "            X_train_trans, y_train = smotetomek_pipeline.fit_resample(X_train_trans, y_train)\n",
    "        elif balmethod == 'no':\n",
    "            print(f\"Bmethod is 'no'\")\n",
    "        else: print('X'*1000)\n",
    "    \n",
    "        # Output the shapes of the balanced datasets\n",
    "        print(f\"Balanced X_train shape: {X_train_trans.shape}\")\n",
    "        print(f\"Balanced y_train shape: {y_train.shape}\")\n",
    "    \n",
    "        X_train = X_train_trans\n",
    "        X_test = X_test_trans\n",
    "        X = X_train\n",
    "        y = y_train\n",
    "        \n",
    "        scores = evaluator.score_models(X_train, y_train, X_test, y_test)\n",
    "        print(scores)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6130170,
     "sourceId": 9965318,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 170908,
     "modelInstanceId": 148393,
     "sourceId": 174310,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 170958,
     "modelInstanceId": 148442,
     "sourceId": 174360,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 832.251631,
   "end_time": "2024-11-22T03:17:44.522468",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-22T03:03:52.270837",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

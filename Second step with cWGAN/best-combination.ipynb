{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8736bae",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-22T12:06:51.466615Z",
     "iopub.status.busy": "2024-11-22T12:06:51.466158Z",
     "iopub.status.idle": "2024-11-22T12:06:52.445589Z",
     "shell.execute_reply": "2024-11-22T12:06:52.444459Z"
    },
    "papermill": {
     "duration": 0.987126,
     "end_time": "2024-11-22T12:06:52.448098",
     "exception": false,
     "start_time": "2024-11-22T12:06:51.460972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/after-cwgan/taiwan_balanced.csv\n",
      "/kaggle/input/after-cwgan/HCDR_test_cwgan.csv\n",
      "/kaggle/input/after-cwgan/HCDR_train_cwgan.csv\n",
      "/kaggle/input/after-cwgan/taiwan_test.csv\n",
      "/kaggle/input/after-cwgan/hmeq_balanced.csv\n",
      "/kaggle/input/after-cwgan/german_test.csv\n",
      "/kaggle/input/after-cwgan/german_balanced.csv\n",
      "/kaggle/input/after-cwgan/hmeq_test.csv\n",
      "/kaggle/input/cwgan/pytorch/default/4/helpers.py\n",
      "/kaggle/input/cwgan/pytorch/default/4/models.py\n",
      "/kaggle/input/cwgan/pytorch/default/4/dataloader.py\n",
      "/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv\n",
      "/kaggle/input/dataset/HCDR_test_cwgan.csv\n",
      "/kaggle/input/dataset/cleaned_hmeq.csv\n",
      "/kaggle/input/dataset/UCI_Credit_Card.csv\n",
      "/kaggle/input/dataset/HCDR_train_cwgan.csv\n",
      "/kaggle/input/dataset/german.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8aef9",
   "metadata": {
    "papermill": {
     "duration": 0.002362,
     "end_time": "2024-11-22T12:06:52.453441",
     "exception": false,
     "start_time": "2024-11-22T12:06:52.451079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We choose these models:\\\n",
    "RandomForestClassifier \\\n",
    "XGBoost\\\n",
    "CatBoost\\\n",
    "LightGBM\\\n",
    "StackingClassifier\\\n",
    "\n",
    "SMOTE (oversampling)\\\n",
    "ClusterCentroid (undersampling)\\\n",
    "SMOTEENN (hybrid: OS and US)\\\n",
    "cWGAN (NN)\\\n",
    "\n",
    "Balanced Random Forest (ensemble)\\\n",
    "Class Weights \\ass Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838e37a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T12:06:52.460951Z",
     "iopub.status.busy": "2024-11-22T12:06:52.460045Z",
     "iopub.status.idle": "2024-11-22T12:06:54.591379Z",
     "shell.execute_reply": "2024-11-22T12:06:54.590288Z"
    },
    "papermill": {
     "duration": 2.137849,
     "end_time": "2024-11-22T12:06:54.593772",
     "exception": false,
     "start_time": "2024-11-22T12:06:52.455923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    make_scorer\n",
    ")\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class ModelEvaluatorWithLibrary:\n",
    "    def __init__(self, models, threshold=0.5, cv_splits=5):\n",
    "        self.models = models\n",
    "        self.threshold = threshold\n",
    "        self.cv_splits = cv_splits\n",
    "\n",
    "    def evaluate_model_with_cv(self, X, y, model, scoring_metrics):\n",
    "        \"\"\"\n",
    "        Perform cross-validation using the provided metrics.\n",
    "        \"\"\"\n",
    "        cv = StratifiedKFold(n_splits=self.cv_splits, shuffle=True, random_state=42)\n",
    "        cv_results = cross_validate(\n",
    "            model, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False\n",
    "        )\n",
    "        \n",
    "        # Mean scores for each metric\n",
    "        model_scores = {metric: cv_results[f'test_{metric}'].mean() for metric in scoring_metrics}\n",
    "        return model_scores\n",
    "\n",
    "    def evaluate_model_on_test(self, X_train, y_train, X_test, y_test, model):\n",
    "        \"\"\"\n",
    "        Train the model and evaluate it on the test set.\n",
    "        \"\"\"\n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test)\n",
    "        y_pred = (y_prob >= self.threshold).astype(int)\n",
    "\n",
    "        scores = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "            'auc_roc': roc_auc_score(y_test, y_prob),\n",
    "        }\n",
    "\n",
    "        return scores, y_pred\n",
    "\n",
    "    def score_models(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate all models on cross-validation and the test set.\n",
    "        \"\"\"\n",
    "        scoring_metrics = {\n",
    "            'f1': 'f1',\n",
    "            'accuracy': 'accuracy',\n",
    "            'auc_roc': 'roc_auc'\n",
    "        }\n",
    "\n",
    "        scores = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Evaluating model: {name}\")\n",
    "            \n",
    "            # Cross-validation scores\n",
    "            cv_scores = self.evaluate_model_with_cv(X_train, y_train, model, scoring_metrics)\n",
    "            \n",
    "            # Test set evaluation\n",
    "            test_scores, y_pred = self.evaluate_model_on_test(X_train, y_train, X_test, y_test, model)\n",
    "            \n",
    "            # Store both cross-validation and test set results\n",
    "            scores[name] = {\n",
    "                #'cross_val': cv_scores,\n",
    "                'test': test_scores\n",
    "            }\n",
    "            \n",
    "            # Plot confusion matrix for the current model\n",
    "            #print(f\"Confusion Matrix for {name}:\")\n",
    "            #self.plot_confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def plot_confusion_matrix(self, y_test, y_pred, labels):\n",
    "        \"\"\"\n",
    "        Plot the confusion matrix.\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec60f4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T12:06:54.600901Z",
     "iopub.status.busy": "2024-11-22T12:06:54.600371Z",
     "iopub.status.idle": "2024-11-22T12:06:54.605356Z",
     "shell.execute_reply": "2024-11-22T12:06:54.604221Z"
    },
    "papermill": {
     "duration": 0.011107,
     "end_time": "2024-11-22T12:06:54.607546",
     "exception": false,
     "start_time": "2024-11-22T12:06:54.596439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91bb6af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T12:06:54.614335Z",
     "iopub.status.busy": "2024-11-22T12:06:54.613921Z",
     "iopub.status.idle": "2024-11-22T12:06:56.437880Z",
     "shell.execute_reply": "2024-11-22T12:06:56.436727Z"
    },
    "papermill": {
     "duration": 1.830584,
     "end_time": "2024-11-22T12:06:56.440663",
     "exception": false,
     "start_time": "2024-11-22T12:06:54.610079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'XGBClassifier': XGBClassifier(random_state=RANDOM_STATE),\n",
    "    'CatBoostClassifier': CatBoostClassifier(verbose=False, random_state=RANDOM_STATE),\n",
    "    'LightGBMClassifier': LGBMClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'StackingClassifier': StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    "            ('xgb', XGBClassifier(random_state=RANDOM_STATE)),\n",
    "            ('catboost', CatBoostClassifier(verbose=False, random_state=RANDOM_STATE)),\n",
    "            ('lgbm', LGBMClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=-1\n",
    "            ))\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=5\n",
    "    )\n",
    "}\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluatorWithLibrary(models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4af61e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T12:06:56.448223Z",
     "iopub.status.busy": "2024-11-22T12:06:56.447607Z",
     "iopub.status.idle": "2024-11-22T13:11:02.550611Z",
     "shell.execute_reply": "2024-11-22T13:11:02.546936Z"
    },
    "papermill": {
     "duration": 3846.121083,
     "end_time": "2024-11-22T13:11:02.564524",
     "exception": false,
     "start_time": "2024-11-22T12:06:56.443441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/after-cwgan/german_balanced.csv\n",
      "BALANCING METHOD: no\n",
      "\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.74, 'f1': 0.43478260869565216, 'auc_roc': 0.764702380952381}}, 'XGBClassifier': {'test': {'accuracy': 0.78, 'f1': 0.5510204081632654, 'auc_roc': 0.7578571428571429}}, 'CatBoostClassifier': {'test': {'accuracy': 0.76, 'f1': 0.5294117647058824, 'auc_roc': 0.7773809523809524}}, 'LightGBMClassifier': {'test': {'accuracy': 0.77, 'f1': 0.5490196078431373, 'auc_roc': 0.7682142857142857}}, 'StackingClassifier': {'test': {'accuracy': 0.75, 'f1': 0.5283018867924527, 'auc_roc': 0.7798809523809523}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/after-cwgan/hmeq_balanced.csv\n",
      "BALANCING METHOD: no\n",
      "\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.9362416107382551, 'f1': 0.8248847926267282, 'auc_roc': 0.9797667494670824}}, 'XGBClassifier': {'test': {'accuracy': 0.9362416107382551, 'f1': 0.8295964125560538, 'auc_roc': 0.9738474005954583}}, 'CatBoostClassifier': {'test': {'accuracy': 0.9295302013422819, 'f1': 0.8073394495412844, 'auc_roc': 0.967113260398499}}, 'LightGBMClassifier': {'test': {'accuracy': 0.9228187919463087, 'f1': 0.7899543378995434, 'auc_roc': 0.9611366559202297}}, 'StackingClassifier': {'test': {'accuracy': 0.9387583892617449, 'f1': 0.8482328482328483, 'auc_roc': 0.9821142293395346}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/after-cwgan/taiwan_balanced.csv\n",
      "BALANCING METHOD: no\n",
      "\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.8135, 'f1': 0.47092198581560285, 'auc_roc': 0.7638571627385011}}, 'XGBClassifier': {'test': {'accuracy': 0.815, 'f1': 0.46737044145873313, 'auc_roc': 0.7667560168235454}}, 'CatBoostClassifier': {'test': {'accuracy': 0.8221666666666667, 'f1': 0.4832929782082324, 'auc_roc': 0.7822500339054335}}, 'LightGBMClassifier': {'test': {'accuracy': 0.8223333333333334, 'f1': 0.47949218749999994, 'auc_roc': 0.7799190655936692}}, 'StackingClassifier': {'test': {'accuracy': 0.8195, 'f1': 0.5163019205002233, 'auc_roc': 0.7829894223110815}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/after-cwgan/HCDR_train_cwgan.csv\n",
      "BALANCING METHOD: no\n",
      "\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.808363784003248, 'f1': 0.22304526748971193, 'auc_roc': 0.647095524087453}}, 'XGBClassifier': {'test': {'accuracy': 0.7592367032074706, 'f1': 0.16801122413188355, 'auc_roc': 0.5799818863301893}}, 'CatBoostClassifier': {'test': {'accuracy': 0.7709602111246447, 'f1': 0.1687235218272242, 'auc_roc': 0.5794461237652464}}, 'LightGBMClassifier': {'test': {'accuracy': 0.7143219650832319, 'f1': 0.17330004405933322, 'auc_roc': 0.5777092984201841}}, 'StackingClassifier': {'test': {'accuracy': 0.8092773041006902, 'f1': 0.21773522064945877, 'auc_roc': 0.6400190508841171}}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "paths = ['/kaggle/input/after-cwgan/german_balanced.csv', '/kaggle/input/after-cwgan/hmeq_balanced.csv', '/kaggle/input/after-cwgan/taiwan_balanced.csv', '/kaggle/input/after-cwgan/HCDR_train_cwgan.csv']\n",
    "#'/kaggle/input/dataset/german.csv', '/kaggle/input/dataset/cleaned_hmeq.csv', '/kaggle/input/dataset/UCI_Credit_Card.csv']#, '/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv']\n",
    "balmethods = ['no']#, 'smote', 'cc', 'smoteenn', 'smotetomek']\n",
    "#pathtest = 'a'\n",
    "for path in paths:\n",
    "    for balmethod in balmethods:\n",
    "        print('-'*100)\n",
    "        print('-'*100)\n",
    "        print(f'DATASET: {path}')\n",
    "        print(f'BALANCING METHOD: {balmethod}')\n",
    "        print('')\n",
    "\n",
    "        if path == '/kaggle/input/after-cwgan/german_balanced.csv':\n",
    "            pathtest = '/kaggle/input/after-cwgan/german_test.csv'\n",
    "        elif path == '/kaggle/input/after-cwgan/hmeq_balanced.csv':\n",
    "            pathtest = '/kaggle/input/after-cwgan/hmeq_test.csv'\n",
    "        elif path == '/kaggle/input/after-cwgan/taiwan_balanced.csv':\n",
    "            pathtest = '/kaggle/input/after-cwgan/taiwan_test.csv'\n",
    "        elif path == '/kaggle/input/after-cwgan/HCDR_train_cwgan.csv':\n",
    "            pathtest = '/kaggle/input/after-cwgan/HCDR_test_cwgan.csv'\n",
    "            \n",
    "        train_df = pd.read_csv(path)\n",
    "        test_df = pd.read_csv(pathtest)\n",
    "        \n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024, stratify=y)\n",
    "    \n",
    "        X_train = train_df.drop('target', axis = 1)\n",
    "        X_test = test_df.drop('target', axis = 1)\n",
    "        y_train = train_df['target']\n",
    "        y_test = test_df['target']\n",
    "        \n",
    "        scores = evaluator.score_models(X_train, y_train, X_test, y_test)\n",
    "        print(scores)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10248411,
     "datasetId": 6142604,
     "sourceId": 9982271,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10248349,
     "datasetId": 6130170,
     "sourceId": 9982212,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10245279,
     "modelInstanceId": 148393,
     "sourceId": 174815,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3854.876903,
   "end_time": "2024-11-22T13:11:03.498460",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-22T12:06:48.621557",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

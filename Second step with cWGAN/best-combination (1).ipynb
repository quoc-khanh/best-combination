{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c97387",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-23T04:31:59.228170Z",
     "iopub.status.busy": "2024-11-23T04:31:59.226781Z",
     "iopub.status.idle": "2024-11-23T04:32:00.210630Z",
     "shell.execute_reply": "2024-11-23T04:32:00.209251Z"
    },
    "papermill": {
     "duration": 0.991982,
     "end_time": "2024-11-23T04:32:00.213203",
     "exception": false,
     "start_time": "2024-11-23T04:31:59.221221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cwgan/pytorch/default/4/helpers.py\n",
      "/kaggle/input/cwgan/pytorch/default/4/models.py\n",
      "/kaggle/input/cwgan/pytorch/default/4/dataloader.py\n",
      "/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv\n",
      "/kaggle/input/dataset/HCDR_test_cwgan.csv\n",
      "/kaggle/input/dataset/cleaned_hmeq.csv\n",
      "/kaggle/input/dataset/UCI_Credit_Card.csv\n",
      "/kaggle/input/dataset/HCDR_train_cwgan.csv\n",
      "/kaggle/input/dataset/german.csv\n",
      "/kaggle/input/after-cwgan/taiwan_balanced.csv\n",
      "/kaggle/input/after-cwgan/HCDR_test_cwgan.csv\n",
      "/kaggle/input/after-cwgan/HCDR_train_cwgan.csv\n",
      "/kaggle/input/after-cwgan/taiwan_test.csv\n",
      "/kaggle/input/after-cwgan/hmeq_balanced.csv\n",
      "/kaggle/input/after-cwgan/german_test.csv\n",
      "/kaggle/input/after-cwgan/german_balanced.csv\n",
      "/kaggle/input/after-cwgan/hmeq_test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce0d663",
   "metadata": {
    "papermill": {
     "duration": 0.002673,
     "end_time": "2024-11-23T04:32:00.219497",
     "exception": false,
     "start_time": "2024-11-23T04:32:00.216824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We choose these models:\\\n",
    "RandomForestClassifier \\\n",
    "XGBoost\\\n",
    "CatBoost\\\n",
    "LightGBM\\\n",
    "StackingClassifier\\\n",
    "\n",
    "SMOTE (oversampling)\\\n",
    "ClusterCentroid (undersampling)\\\n",
    "SMOTEENN (hybrid: OS and US)\\\n",
    "cWGAN (NN)\\\n",
    "\n",
    "Balanced Random Forest (ensemble)\\\n",
    "Class Weights \\ass Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b45dbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T04:32:00.228124Z",
     "iopub.status.busy": "2024-11-23T04:32:00.226739Z",
     "iopub.status.idle": "2024-11-23T04:32:02.360552Z",
     "shell.execute_reply": "2024-11-23T04:32:02.359309Z"
    },
    "papermill": {
     "duration": 2.140968,
     "end_time": "2024-11-23T04:32:02.363393",
     "exception": false,
     "start_time": "2024-11-23T04:32:00.222425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# SMOTE for oversampling\n",
    "smote_pipeline = make_pipeline(\n",
    "    SMOTE()  # Apply SMOTE to oversample the minority class\n",
    ")\n",
    "\n",
    "# ClusterCentroids for undersampling\n",
    "cluster_centroid_pipeline = make_pipeline(\n",
    "    ClusterCentroids()  # Apply ClusterCentroids to undersample the majority class\n",
    ")\n",
    "\n",
    "# SMOTEENN for hybrid oversampling and undersampling\n",
    "smoteenn_pipeline = make_pipeline(\n",
    "    SMOTEENN()  # Apply SMOTEENN to balance the dataset\n",
    ")\n",
    "\n",
    "# SMOTETomek for hybrid oversampling and undersampling\n",
    "smotetomek_pipeline = make_pipeline(\n",
    "    SMOTETomek()  # Apply SMOTETomek to balance the dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e3abdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T04:32:02.371357Z",
     "iopub.status.busy": "2024-11-23T04:32:02.370796Z",
     "iopub.status.idle": "2024-11-23T04:32:02.881276Z",
     "shell.execute_reply": "2024-11-23T04:32:02.880147Z"
    },
    "papermill": {
     "duration": 0.517252,
     "end_time": "2024-11-23T04:32:02.883811",
     "exception": false,
     "start_time": "2024-11-23T04:32:02.366559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    make_scorer\n",
    ")\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class ModelEvaluatorWithLibrary:\n",
    "    def __init__(self, models, threshold=0.5, cv_splits=5):\n",
    "        self.models = models\n",
    "        self.threshold = threshold\n",
    "        self.cv_splits = cv_splits\n",
    "\n",
    "    def evaluate_model_with_cv(self, X, y, model, scoring_metrics):\n",
    "        \"\"\"\n",
    "        Perform cross-validation using the provided metrics.\n",
    "        \"\"\"\n",
    "        cv = StratifiedKFold(n_splits=self.cv_splits, shuffle=True, random_state=42)\n",
    "        cv_results = cross_validate(\n",
    "            model, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False\n",
    "        )\n",
    "        \n",
    "        # Mean scores for each metric\n",
    "        model_scores = {metric: cv_results[f'test_{metric}'].mean() for metric in scoring_metrics}\n",
    "        return model_scores\n",
    "\n",
    "    def evaluate_model_on_test(self, X_train, y_train, X_test, y_test, model):\n",
    "        \"\"\"\n",
    "        Train the model and evaluate it on the test set.\n",
    "        \"\"\"\n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test)\n",
    "        y_pred = (y_prob >= self.threshold).astype(int)\n",
    "\n",
    "        scores = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "            'auc_roc': roc_auc_score(y_test, y_prob),\n",
    "        }\n",
    "\n",
    "        return scores, y_pred\n",
    "\n",
    "    def score_models(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate all models on cross-validation and the test set.\n",
    "        \"\"\"\n",
    "        scoring_metrics = {\n",
    "            'f1': 'f1',\n",
    "            'accuracy': 'accuracy',\n",
    "            'auc_roc': 'roc_auc'\n",
    "        }\n",
    "\n",
    "        scores = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Evaluating model: {name}\")\n",
    "            \n",
    "            # Cross-validation scores\n",
    "            cv_scores = self.evaluate_model_with_cv(X_train, y_train, model, scoring_metrics)\n",
    "            \n",
    "            # Test set evaluation\n",
    "            test_scores, y_pred = self.evaluate_model_on_test(X_train, y_train, X_test, y_test, model)\n",
    "            \n",
    "            # Store both cross-validation and test set results\n",
    "            scores[name] = {\n",
    "                #'cross_val': cv_scores,\n",
    "                'test': test_scores\n",
    "            }\n",
    "            \n",
    "            # Plot confusion matrix for the current model\n",
    "            #print(f\"Confusion Matrix for {name}:\")\n",
    "            #self.plot_confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def plot_confusion_matrix(self, y_test, y_pred, labels):\n",
    "        \"\"\"\n",
    "        Plot the confusion matrix.\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd39189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T04:32:02.891699Z",
     "iopub.status.busy": "2024-11-23T04:32:02.891183Z",
     "iopub.status.idle": "2024-11-23T04:32:02.896657Z",
     "shell.execute_reply": "2024-11-23T04:32:02.895537Z"
    },
    "papermill": {
     "duration": 0.012118,
     "end_time": "2024-11-23T04:32:02.899137",
     "exception": false,
     "start_time": "2024-11-23T04:32:02.887019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c802c9bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T04:32:02.907539Z",
     "iopub.status.busy": "2024-11-23T04:32:02.907134Z",
     "iopub.status.idle": "2024-11-23T04:32:04.448785Z",
     "shell.execute_reply": "2024-11-23T04:32:04.447832Z"
    },
    "papermill": {
     "duration": 1.548727,
     "end_time": "2024-11-23T04:32:04.451243",
     "exception": false,
     "start_time": "2024-11-23T04:32:02.902516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'XGBClassifier': XGBClassifier(random_state=RANDOM_STATE),\n",
    "    'CatBoostClassifier': CatBoostClassifier(verbose=False, random_state=RANDOM_STATE),\n",
    "    'LightGBMClassifier': LGBMClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'StackingClassifier': StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    "            ('xgb', XGBClassifier(random_state=RANDOM_STATE)),\n",
    "            ('catboost', CatBoostClassifier(verbose=False, random_state=RANDOM_STATE)),\n",
    "            ('lgbm', LGBMClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=-1\n",
    "            ))\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=5\n",
    "    )\n",
    "}\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluatorWithLibrary(models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d5c530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T04:32:04.459843Z",
     "iopub.status.busy": "2024-11-23T04:32:04.459290Z",
     "iopub.status.idle": "2024-11-23T09:49:16.796271Z",
     "shell.execute_reply": "2024-11-23T09:49:16.784096Z"
    },
    "papermill": {
     "duration": 19032.384649,
     "end_time": "2024-11-23T09:49:16.839222",
     "exception": false,
     "start_time": "2024-11-23T04:32:04.454573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DATASET: /kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv\n",
      "BALANCING METHOD: no\n",
      "\n",
      "TARGET\n",
      "90596\n",
      "7922\n",
      "Bmethod is 'no'\n",
      "Balanced X_train shape: (78814, 1358)\n",
      "Balanced y_train shape: (78814,)\n",
      "Evaluating model: RandomForestClassifier\n",
      "Evaluating model: XGBClassifier\n",
      "Evaluating model: CatBoostClassifier\n",
      "Evaluating model: LightGBMClassifier\n",
      "Evaluating model: StackingClassifier\n",
      "{'RandomForestClassifier': {'test': {'accuracy': 0.9260556232237109, 'f1': 0.14944541739638062, 'auc_roc': 0.7026160995997502}}, 'XGBClassifier': {'test': {'accuracy': 0.9195594803085668, 'f1': 0.09994321408290745, 'auc_roc': 0.708456024789841}}, 'CatBoostClassifier': {'test': {'accuracy': 0.9201684937068616, 'f1': 0.05183845690174804, 'auc_roc': 0.7232423573483177}}, 'LightGBMClassifier': {'test': {'accuracy': 0.9194072269589931, 'f1': 0.03170731707317073, 'auc_roc': 0.7170143940787568}}, 'StackingClassifier': {'test': {'accuracy': 0.9251928542427933, 'f1': 0.20410367170626353, 'auc_roc': 0.7312835167346757}}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "paths = ['/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv']\n",
    "#'/kaggle/input/dataset/german.csv', '/kaggle/input/dataset/cleaned_hmeq.csv', '/kaggle/input/dataset/UCI_Credit_Card.csv']#, \n",
    "balmethods = ['no']#, 'smote', 'cc', 'smoteenn', 'smotetomek']\n",
    "for path in paths:\n",
    "    for balmethod in balmethods:\n",
    "        print('-'*100)\n",
    "        print('-'*100)\n",
    "        print(f'DATASET: {path}')\n",
    "        print(f'BALANCING METHOD: {balmethod}')\n",
    "        print('')\n",
    "        df = pd.read_csv(path)\n",
    "    \n",
    "        df = df.replace([np.inf, -np.inf], 0)\n",
    "        \n",
    "        if path == '/kaggle/input/dataset/german.csv':\n",
    "            target_col = 'Status_loan'\n",
    "            #df = df.drop('')\n",
    "        elif path == '/kaggle/input/dataset/cleaned_hmeq.csv':\n",
    "            target_col = 'BAD'\n",
    "            #df = df.drop('')\n",
    "        elif path == '/kaggle/input/dataset/UCI_Credit_Card.csv':\n",
    "            target_col = 'default.payment.next.month'\n",
    "            df = df.drop('ID', axis=1)\n",
    "        elif path == '/kaggle/input/dataset/FinalDatasetHomeCreditDefaultRisk.csv':\n",
    "            target_col = 'TARGET'\n",
    "            df = df.drop('SK_ID_CURR', axis=1)\n",
    "            y = df[target_col]\n",
    "            df, temp = train_test_split(df, test_size=0.6, random_state=2024, stratify=y) #thuc hanh tren bo nho 100000 (/200000) samples\n",
    "            del temp, y\n",
    "        \n",
    "        # Define columns dynamically based on data types\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        \n",
    "        # Remove target column from cat_cols or num_cols if present\n",
    "        if target_col in cat_cols:\n",
    "            cat_cols.remove(target_col)\n",
    "        elif target_col in num_cols:\n",
    "            num_cols.remove(target_col)\n",
    "        for col in cat_cols:\n",
    "            df[col] = df[col].astype(str)\n",
    "        \n",
    "        X = df.loc[:, num_cols + cat_cols]\n",
    "        y = df[target_col]\n",
    "        \n",
    "        print(target_col)\n",
    "        print(y[y==0].count())\n",
    "        print(y[y==1].count())\n",
    " \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024, stratify=y)\n",
    "        \n",
    "        # Define numerical and categorical column transformers\n",
    "        num_prep = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                                 MinMaxScaler())\n",
    "        \n",
    "        # Using OrdinalEncoder for numerical-like encoding of categorical columns\n",
    "        cat_prep = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
    "                                 OneHotEncoder())\n",
    "        \n",
    "        # Combine both transformers into a ColumnTransformer\n",
    "        prep = ColumnTransformer([\n",
    "            ('num', num_prep, num_cols),\n",
    "            ('cat', cat_prep, cat_cols)\n",
    "            ],\n",
    "            remainder='drop')\n",
    "        \n",
    "        # Apply transformations to training and test sets\n",
    "        X_train_trans = prep.fit_transform(X_train)\n",
    "        X_test_trans = prep.transform(X_test)\n",
    "        if balmethod == 'smote':\n",
    "            X_train_trans, y_train = smote_pipeline.fit_resample(X_train_trans, y_train)\n",
    "        elif balmethod == 'cc':\n",
    "            X_train_trans, y_train = cluster_centroid_pipeline.fit_resample(X_train_trans, y_train)\n",
    "        elif balmethod == 'smoteenn':\n",
    "            X_train_trans, y_train = smoteenn_pipeline.fit_resample(X_train_trans, y_train)\n",
    "        elif balmethod == 'smotetomek':\n",
    "            X_train_trans, y_train = smotetomek_pipeline.fit_resample(X_train_trans, y_train)\n",
    "        elif balmethod == 'no':\n",
    "            print(f\"Bmethod is 'no'\")\n",
    "        else: print('X'*1000)\n",
    "    \n",
    "        # Output the shapes of the balanced datasets\n",
    "        print(f\"Balanced X_train shape: {X_train_trans.shape}\")\n",
    "        print(f\"Balanced y_train shape: {y_train.shape}\")\n",
    "    \n",
    "        X_train = X_train_trans\n",
    "        X_test = X_test_trans\n",
    "        X = X_train\n",
    "        y = y_train\n",
    "        \n",
    "        scores = evaluator.score_models(X_train, y_train, X_test, y_test)\n",
    "        print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b300c6f6",
   "metadata": {
    "papermill": {
     "duration": 0.004136,
     "end_time": "2024-11-23T09:49:16.847902",
     "exception": false,
     "start_time": "2024-11-23T09:49:16.843766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6130170,
     "sourceId": 9982212,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6142604,
     "sourceId": 9982271,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 170908,
     "modelInstanceId": 148393,
     "sourceId": 174815,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19042.18959,
   "end_time": "2024-11-23T09:49:18.692616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-23T04:31:56.503026",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
